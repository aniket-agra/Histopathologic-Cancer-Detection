{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import gc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "%matplotlib inline\n",
    "\n",
    "base = '/kaggle/input/histopathologic-cancer-detection/'\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         id  label\n",
      "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
      "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
      "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
      "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
      "4  068aba587a4950175d04c680d38943fd488d6a9d      0\n",
      "5  acfe80838488fae3c89bd21ade75be5c34e66be7      0\n",
      "6  a24ce148f6ffa7ef8eefb4efb12ebffe8dd700da      1\n",
      "7  7f6ccae485af121e0b6ee733022e226ee6b0c65f      1\n",
      "8  559e55a64c9ba828f700e948f6886f4cea919261      0\n",
      "9  8eaaa7a400aa79d36c2440a4aa101cc14256cda4      0\n",
      "220025\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(base+'train_labels.csv')\n",
    "print(labels.head(10))\n",
    "print(len(labels))\n",
    "\n",
    "def load_data(idx) : \n",
    "    N = len(idx)\n",
    "    X = np.empty([N, 96, 96, 3], dtype = np.uint8)\n",
    "    y = np.squeeze([labels['label'][i] for i in idx])\n",
    "    for i in range(N) : \n",
    "        X[i] = cv2.imread(base+'train/{}.tif'.format(labels['id'][idx[i]]))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220025, 96, 96, 3) (220025,)\n"
     ]
    }
   ],
   "source": [
    "N = len(labels)\n",
    "idx = np.arange(len(labels))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx)\n",
    "idx_cut = idx[0:N]\n",
    "X, y = load_data(idx_cut)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "positives = y == 1\n",
    "fig = plt.figure(figsize=(10, 4), dpi=150)\n",
    "np.random.seed(100) #we can use the seed to get a different set of random images\n",
    "for plotNr,idx in enumerate(np.random.randint(0,N,8)):\n",
    "    ax = fig.add_subplot(2, 8//2, plotNr+1, xticks=[], yticks=[]) #add subplots\n",
    "    plt.imshow(X[idx]) #plot image\n",
    "    ax.set_title('Label: ' + str(y[idx])) #show the label corresponding to the image\n",
    "nbins = 256\n",
    "colordic = {0 : 'R', 1 : 'G', 2 : 'B'}\n",
    "fig, axs = plt.subplots(3, 2, figsize = (8, 8), sharey = True, dpi = 150)\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "for i in range(3) : \n",
    "    i2 = 2*i\n",
    "    ax = axs[i, 0]\n",
    "    ax.hist(X[positives, :, :, i].flatten(), bins = nbins, density = True)\n",
    "    ax.set_title('{} channel Positives'.format(colordic[i]), color = 'white')\n",
    "    ax.tick_params(axis = 'both', colors = 'white')\n",
    "    ax = axs[i, 1]\n",
    "    ax.hist(X[~positives, :, :, i].flatten(), bins = nbins, density = True)\n",
    "    ax.set_title('{} channel Negatives'.format(colordic[i]), color = 'white')\n",
    "    ax.tick_params(axis = 'both', colors = 'white')\n",
    "nbins = 64\n",
    "fig, axs = plt.subplots(1, 2, sharey = True, figsize = (8, 2), dpi = 150)\n",
    "axs[0].hist(np.mean(X[positives], axis = (1, 2, 3)).flatten(), bins = nbins, density = True)\n",
    "axs[0].set_title('Mean Brightness of Positives', color = 'white')\n",
    "axs[0].tick_params(axis = 'both', colors = 'white')\n",
    "axs[1].hist(np.mean(X[~positives], axis = (1, 2, 3)).flatten(), bins = nbins, density = True)\n",
    "axs[1].set_title('Mean Brightness of Negatives', color = 'white')\n",
    "axs[1].tick_params(axis = 'both', colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 96, 96, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 96, 96, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 96, 96, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,475,601\n",
      "Trainable params: 1,474,641\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filters = [3, 3, 3, 3, 3, 3, 3]\n",
    "strid = [1, 1, 1]\n",
    "pool = [2, 2, 2, 2, 2, 2, 2]\n",
    "chan = [8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "data_for = 'channels_last'\n",
    "model = Sequential()\n",
    "\n",
    "i = 1\n",
    "model.add(Conv2D(chan[i], (filters[i], filters[i]), padding = 'same', input_shape = [96, 96, 3]))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(chan[i], (filters[i], filters[i]), padding = 'same'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (pool[i], pool[i])))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "for i in range(2, 5) : \n",
    "    model.add(Conv2D(chan[i], (filters[i], filters[i]), padding = 'same'))\n",
    "    model.add(BatchNormalization(axis = -1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(chan[i], (filters[i], filters[i]), padding = 'same'))\n",
    "    model.add(BatchNormalization(axis = -1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (pool[i], pool[i])))\n",
    "    model.add(Dropout(0.25))\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(chan[-3]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0007), \n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(curve = 'PR'), tf.keras.metrics.AUC(curve = 'ROC')])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now take off some indices as a validation set. The parameter 0.2 represents the fraction of data to treat as validation set. The strategy is to generate nvals random numbers between 0 and total size of data, and use those as indices for validation data. We subtract these indices from a list from 0 to total size to get indices for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training epoch 0: 100%|██████████| 3600/3600 [03:00<00:00, 19.93it/s, acc=0.85, auc_pr=0.84, auc_roc=0.88, loss=0.39]\n",
      "Running training epoch 1: 100%|██████████| 3600/3600 [02:50<00:00, 21.09it/s, acc=0.87, auc_pr=0.87, auc_roc=0.91, loss=0.27]\n",
      "Running training epoch 2: 100%|██████████| 3600/3600 [02:50<00:00, 21.08it/s, acc=0.88, auc_pr=0.89, auc_roc=0.92, loss=0.15]\n",
      "Running training epoch 3: 100%|██████████| 3600/3600 [02:51<00:00, 21.03it/s, acc=0.89, auc_pr=0.90, auc_roc=0.92, loss=0.09]\n",
      "Running training epoch 4: 100%|██████████| 3600/3600 [02:53<00:00, 20.79it/s, acc=0.90, auc_pr=0.91, auc_roc=0.93, loss=0.23]\n",
      "Running training epoch 5: 100%|██████████| 3600/3600 [02:53<00:00, 20.76it/s, acc=0.90, auc_pr=0.91, auc_roc=0.93, loss=0.23]\n",
      "Running training epoch 6: 100%|██████████| 3600/3600 [02:54<00:00, 20.60it/s, acc=0.91, auc_pr=0.92, auc_roc=0.94, loss=0.41]\n",
      "Running training epoch 7: 100%|██████████| 3600/3600 [02:54<00:00, 20.65it/s, acc=0.91, auc_pr=0.92, auc_roc=0.94, loss=0.27]\n",
      "Running training epoch 8: 100%|██████████| 3600/3600 [02:51<00:00, 21.03it/s, acc=0.91, auc_pr=0.93, auc_roc=0.94, loss=0.11]\n",
      "Running training epoch 9: 100%|██████████| 3600/3600 [02:50<00:00, 21.09it/s, acc=0.92, auc_pr=0.93, auc_roc=0.95, loss=0.24]\n"
     ]
    }
   ],
   "source": [
    "nvals = int(np.floor(0.2 * len(X)))\n",
    "np.random.seed(1)\n",
    "valid_indx = np.random.randint(0, len(X), nvals)\n",
    "train_indx = np.delete(np.arange(len(X)), valid_indx)\n",
    "\n",
    "epoch_num = 10\n",
    "batch_size = 50\n",
    "num_batch = int(np.floor(len(train_indx)/batch_size))\n",
    "\n",
    "x_batch = np.empty([batch_size, 96, 96, 3], dtype = np.uint8)\n",
    "y_batch = np.empty([batch_size])\n",
    "for i in range(epoch_num) : \n",
    "    np.random.shuffle(train_indx)           \n",
    "    with trange(num_batch) as t : \n",
    "        for j in t : \n",
    "            start = j * batch_size\n",
    "            indxes = train_indx[start : start + batch_size]\n",
    "            x_batch = X[indxes]\n",
    "            y_batch = y[indxes]\n",
    "            metrics = model.train_on_batch(x_batch, y_batch, reset_metrics = False)    \n",
    "            t.set_description('Running training epoch ' + str(i)) #set progressbar title\n",
    "            t.set_postfix(loss=\"%.2f\" % round(metrics[0], 2), \n",
    "                          acc=\"%.2f\" % round(metrics[1], 2), \n",
    "                          auc_pr = \"%.2f\" % round(metrics[2], 2), \n",
    "                          auc_roc = \"%.2f\" % round(metrics[3], 2)) #display metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = X_train, y = y_train, batch_size = 50, epochs = 10, verbose = 1, validation_data=(X_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_batch = int(np.floor(nvals/batch_size))\n",
    "\n",
    "with trange(num_batch) as t : \n",
    "    for j in t : \n",
    "        start = j * batch_size\n",
    "        indxes = valid_indx[start : start + batch_size]\n",
    "        x_batch = X[indxes]\n",
    "        y_batch = y[indxes]\n",
    "        metrics = model.test_on_batch(x_batch, y_batch, reset_metrics = False)    \n",
    "        t.set_description('Running validation epoch ') #set progressbar title\n",
    "        t.set_postfix(loss=\"%.2f\" % round(metrics[0], 2),\n",
    "                      acc=\"%.2f\" % round(metrics[1], 2),\n",
    "                     auc = \"%.2f\" % round(metrics[2], 2)) #display metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dense layer with same number of output neurons as last CNN layer seems to hamper learning - accuracy and loss stay more or less constant in this case. With a 4x larger layer we find a similar pattern - now accuracy increases but really slowly. The 2x pattern seems to hit a sweet spot. WHY?! Could be because our eyes probably perceive regions on log scale? Well brightness they do...\n",
    "2. There's a sweet spot for number of parameters and actual architecture. Starting with 16 and ending at 256 for Conv layers works best.\n",
    "3. Adding BatchNorm pushes accuracy to 0.83 in first epoch! Similar spike for PR and ROC AUC. Overall much better model with BatchNorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 0 - 5000\n",
      "5000/5000 [==============================] - 1s 295us/step\n",
      "Indexes: 5000 - 10000\n",
      "5000/5000 [==============================] - 1s 293us/step\n",
      "Indexes: 10000 - 15000\n",
      "5000/5000 [==============================] - 1s 291us/step\n",
      "Indexes: 15000 - 20000\n",
      "5000/5000 [==============================] - 1s 293us/step\n",
      "Indexes: 20000 - 25000\n",
      "5000/5000 [==============================] - 2s 300us/step\n",
      "Indexes: 25000 - 30000\n",
      "5000/5000 [==============================] - 1s 296us/step\n",
      "Indexes: 30000 - 35000\n",
      "5000/5000 [==============================] - 1s 294us/step\n",
      "Indexes: 35000 - 40000\n",
      "5000/5000 [==============================] - 1s 297us/step\n",
      "Indexes: 40000 - 45000\n",
      "5000/5000 [==============================] - 1s 291us/step\n",
      "Indexes: 45000 - 50000\n",
      "5000/5000 [==============================] - 1s 291us/step\n",
      "Indexes: 50000 - 55000\n",
      "5000/5000 [==============================] - 1s 298us/step\n",
      "Indexes: 55000 - 60000\n",
      "2458/2458 [==============================] - 1s 350us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc308167f29b617cac141c34a7643a4fb86eb3ff</td>\n",
       "      <td>0.927498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68084861d7deeeeaf1669068a09f69aecfb51709</td>\n",
       "      <td>0.941825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b693e5fe5432918c7924088449957e7e33fb3121</td>\n",
       "      <td>0.047461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a6d81cc35bd175ef955d794b6d948ee728e4be13</td>\n",
       "      <td>0.007930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1e6671e498b7a8680812b8b1296cda5a9240975</td>\n",
       "      <td>0.204908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id     label\n",
       "0  dc308167f29b617cac141c34a7643a4fb86eb3ff  0.927498\n",
       "1  68084861d7deeeeaf1669068a09f69aecfb51709  0.941825\n",
       "2  b693e5fe5432918c7924088449957e7e33fb3121  0.047461\n",
       "3  a6d81cc35bd175ef955d794b6d948ee728e4be13  0.007930\n",
       "4  f1e6671e498b7a8680812b8b1296cda5a9240975  0.204908"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test_dir = base + 'test/' #specify test data folder\n",
    "test_files = glob.glob(base_test_dir+'*.tif') #find the test file names\n",
    "submission = pd.DataFrame() #create a dataframe to hold results\n",
    "file_batch = 5000 #we will predict 5000 images at a time\n",
    "max_idx = len(test_files) #last index to use\n",
    "for idx in range(0, max_idx, file_batch): #iterate over test image batches\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]}) #add the filenames to the dataframe\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[-1].split(\".\")[0]) #add the ids to the dataframe\n",
    "    test_df['image'] = test_df['path'].map(cv2.imread) #read the batch\n",
    "    K_test = np.stack(test_df[\"image\"].values) #convert to numpy array\n",
    "    predictions = model.predict(K_test,verbose = 1) #predict the labels for the test data\n",
    "    test_df['label'] = predictions #store them in the dataframe\n",
    "    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n",
    "submission.head() #display first lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
